{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a4a3e14-0b4f-4622-be9f-11e59a1a8eb3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# RAG-LLM Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94801c0f-88d4-4d6b-878f-a849a563a3b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Project explanation/use case\n",
    "\n",
    "The fictitious use case for this project is to generate responses to interact with a child. Suppose that the child were speaking to an AI agent. The child should be able to direct questions towards one of the following characters from Alice in Wonderland: Alice, the Queen of Hearts, the Mad Hatter, the Cheshire Cat, the White Rabbit, or the Caterpillar; and the agent will respond in the voice of the specified character.\n",
    "\n",
    "**DO NOT RUN THE NOTEBOOK**, as I have deleted my OpenAI API key from this notebook and the LLM will not retrieve content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2d3e99d-e6be-4819-af14-37c3f07b44bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31403b74-91a0-45b1-8b41-3622b586c031",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "petastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\n",
      "databricks-feature-store 0.14.3 requires pyspark<4,>=3.1.2, which is not installed.\n",
      "ydata-profiling 4.2.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.4 which is incompatible.\n",
      "mlflow-skinny 2.5.0 requires importlib-metadata!=4.7.0,<7,>=3.7.0, but you have importlib-metadata 7.1.0 which is incompatible.\n",
      "mlflow-skinny 2.5.0 requires packaging<24, but you have packaging 24.1 which is incompatible.\n",
      "mleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 1.1.1 which is incompatible.\n",
      "google-auth 1.33.0 requires cachetools<5.0,>=2.0.0, but you have cachetools 5.3.3 which is incompatible.\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade transformers>=4.31.0 --upgrade chromadb==0.3.29 langchain-community mlflow langchain-openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef8c4d1-b130-40d9-8756-1dfeb7f674db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import requests\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82d87b29-55b9-40a0-8518-aa379e5d8cac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Chroma client\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_client.heartbeat()\n",
    "\n",
    "# Create collection\n",
    "collection = chroma_client.create_collection(name='alice_in_wonderland',\n",
    "                                             metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a46f498e-1526-4936-937a-851b71530312",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Note that the above step involved a decision to use cosine distance as the similarity metric between tokenized document embeddings. This decision was arbitrary, and part of model improvement might involve trying other distance calculations like, for example, L2 distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26f17f35-c238-434a-8773-0f9e542565fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fffe710-06b2-42b2-ac42-6ca896b283ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# URL of the .txt file\n",
    "url = 'https://www.gutenberg.org/cache/epub/11/pg11.txt'\n",
    "\n",
    "# Instantiate corpus text\n",
    "corpus = GutenbergLoader(\"https://www.gutenberg.org/cache/epub/11/pg11.txt\").load()\n",
    "# Remove all the new lines to make viewing denser\n",
    "clean_corpus = corpus[0].dict()['page_content'].replace('\\r', '').replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a24c5761-2e7a-41ac-91e1-b3352f134d0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Alice's Adventures in Wonderland          This ebook is for the use of anyone anywhere in the United States and   most other parts of the world at no cost and with almost no restrictions   whatsoever. You may copy it, give it away or re-use it under the terms   of the Project Gutenberg License included with this ebook or online   at www.gutenberg.org. If you are not located in the United States,   you will have to check the laws of the country where you are located\n"
     ]
    }
   ],
   "source": [
    "print(clean_corpus[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0edd3c8e-0cf3-45d6-881f-b1f5060705d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Chunk the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e514295e-de40-4113-988e-b5e4c667d792",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=75,\n",
    "    length_function=len,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(clean_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4080f28a-ce2b-4dbb-aa4a-d6c5fc9c1130",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Splitting the corpus into documents, or \"chunks,\" involves other largely (though not entirely) arbitrary decisions: `chunk_size` and `chunk_overlap`. Smaller chunks with more overlap allow for a more granular search over the embeddings, but they increase the likelihood of getting repeated information in the returned context and of missing important contextual information found in longer chunks. \n",
    "\n",
    "These parameters can be modifed to check for model improvement, but only as long as they remain within the allowed length limit. In this case, the embedding model truncates input text longer than 256 word pieces by default. 250-character chunks are well within the 256-word-piece limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "058c6011-d8b0-45a0-929b-e66ec42c97d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in her lessons in the schoolroom, and though this was not a _very_ good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) “—yes, that’s about the right distance—but then I'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine a random chunk\n",
    "chunks[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0949c21c-f4db-4d1a-8562-ed756d720d80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Add the chunks to a Chroma collection\n",
    "\n",
    "By default, the chunks are embedded using the [all-MiniLM-L6-v2 sentence-transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d5350f-de13-47bd-8f88-5385711d7795",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   0%|          | 0.00/79.3M [00:00<?, ?iB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   0%|          | 51.0k/79.3M [00:00<03:17, 420kiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   0%|          | 114k/79.3M [00:00<02:53, 479kiB/s] \r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   0%|          | 193k/79.3M [00:00<02:28, 558kiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   0%|          | 278k/79.3M [00:00<02:14, 614kiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   1%|          | 543k/79.3M [00:00<01:09, 1.18MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   2%|▏         | 1.67M/79.3M [00:00<00:20, 4.06MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   5%|▌         | 4.20M/79.3M [00:00<00:07, 10.1MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:   9%|▉         | 7.22M/79.3M [00:00<00:04, 15.2MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  13%|█▎        | 10.2M/79.3M [00:01<00:03, 18.5MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  17%|█▋        | 13.3M/79.3M [00:01<00:03, 20.7MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  20%|█▉        | 15.5M/79.3M [00:01<00:03, 21.4MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  23%|██▎       | 17.9M/79.3M [00:01<00:02, 22.5MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  26%|██▌       | 20.5M/79.3M [00:01<00:02, 23.0MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  30%|██▉       | 23.5M/79.3M [00:01<00:02, 23.9MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  33%|███▎      | 26.5M/79.3M [00:01<00:02, 24.3MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  37%|███▋      | 29.5M/79.3M [00:01<00:02, 24.6MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  41%|████      | 32.5M/79.3M [00:02<00:01, 24.9MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  45%|████▍     | 35.3M/79.3M [00:02<00:01, 24.7MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  48%|████▊     | 38.4M/79.3M [00:02<00:01, 24.9MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  52%|█████▏    | 41.4M/79.3M [00:02<00:01, 25.0MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  56%|█████▌    | 44.4M/79.3M [00:02<00:01, 25.2MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  60%|█████▉    | 47.4M/79.3M [00:02<00:01, 25.4MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  63%|██████▎   | 50.2M/79.3M [00:02<00:01, 26.3MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  66%|██████▋   | 52.7M/79.3M [00:02<00:01, 24.9MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  69%|██████▉   | 55.1M/79.3M [00:02<00:01, 24.3MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  73%|███████▎  | 57.8M/79.3M [00:03<00:00, 25.3MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  76%|███████▋  | 60.7M/79.3M [00:03<00:00, 26.6MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  80%|███████▉  | 63.2M/79.3M [00:03<00:00, 25.3MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  83%|████████▎ | 65.7M/79.3M [00:03<00:00, 24.6MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  86%|████████▋ | 68.4M/79.3M [00:03<00:00, 25.6MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  90%|████████▉ | 71.1M/79.3M [00:03<00:00, 26.2MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  93%|█████████▎| 73.6M/79.3M [00:03<00:00, 24.6MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz:  96%|█████████▌| 76.0M/79.3M [00:03<00:00, 24.8MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|█████████▉| 79.0M/79.3M [00:03<00:00, 25.9MiB/s]\r",
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:03<00:00, 20.9MiB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add document to collection\n",
    "collection.add(\n",
    "    documents=chunks,\n",
    "    ids=([f'Chunk {index}' for index, _ in enumerate(chunks)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e57572ac-d621-4dc8-afd5-e9be9ac42bf5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rather timidly, saying to herself “Suppose it should be raving mad after all! I almost wish I’d gone to see the Hatter instead!”     CHAPTER VII. A Mad Tea-Party   There was a table set out under a tree in front of the house, and the March Hare and'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=['Mad Hatter, what is your favorite food?'],\n",
    "    n_results=8\n",
    ")\n",
    "# Examine top-ranked document\n",
    "results['documents'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3f17fdc-7cc2-4eea-aa80-ffc696a95bd8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Character identity management \n",
    "\n",
    "The next three steps are to simulate the needs of the project's use case. A child must \"activate\" (assign) a character so the AI agent knows which persona to embody in its response. Let us suppose this activation phrase is \"Hey {character}, ....\" The following function will check if a character has been activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd8f7c2-a08b-434f-99f6-75ecc0ddbab2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheshire cat\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def character_activation_check(string):\n",
    "    '''\n",
    "    Check for activation phrase and ID character if activated.\n",
    "    '''\n",
    "    activation_list = [f'hey {character}' for character in ['queen of hearts', 'mad hatter', 'alice', 'cheshire cat', 'white rabbit', 'caterpillar']]\n",
    "    for element in activation_list:\n",
    "        if element in string:\n",
    "            return element[4:]\n",
    "    return False\n",
    "\n",
    "query_1 = 'hey cheshire cat, what is your favorite food?'\n",
    "query_2 = 'cheshire cat, what is your favorite food?'\n",
    "\n",
    "print(character_activation_check(query_1))\n",
    "print(character_activation_check(query_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeaaf5f1-7778-4640-a13d-7e5adf040e40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The second step is to help with the AI agent's identity permanence. If the previous interaction resulted in a character activation, then conversation can continue without the need for the child to say the character's name again. This could later be made more robust to include, for example, time limits so the identity resets after a specified duration of non-interaction.\n",
    "\n",
    "I'm sure there are canonical ways of dealing with this. However, I don't have experience working with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2f67ca2-c625-4ea0-9cb1-0cee2677d4e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assigned_character = None\n",
    "\n",
    "def assign_character(query):\n",
    "    '''\n",
    "    Assign a character or prompt the user to use correct assignment phrasing.\n",
    "    '''\n",
    "    global assigned_character\n",
    "    \n",
    "    # Check if the query contains an activation phrase\n",
    "    query = query.lower()\n",
    "    result = character_activation_check(query)\n",
    "    \n",
    "    if result:\n",
    "        # Reassign the assigned_character variable to the function output\n",
    "        assigned_character = result\n",
    "        return assigned_character\n",
    "    elif assigned_character is not None:\n",
    "        # Do nothing if assigned_character is already set\n",
    "        return assigned_character\n",
    "    else:\n",
    "        # Return None if no character assigned\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55c7ac91-1627-40d8-8723-512b86fa5ed9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The final step of this process is to generate the retrieval-agumented context text. This is where the user query is used to retrieve context text from the corpus, which is appended to additional guiding instructions along with the original user query. Also at this step is an alert to the user in the event that a character has not been activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc7b909d-010f-4efa-b512-1f8613841202",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_context_text(query):\n",
    "    character = assign_character(query)\n",
    "    if character is not None:\n",
    "        pass\n",
    "    else:\n",
    "        return \"Sorry, to talk to a character, say 'Hey {character},' followed by what you want to say.\"\n",
    "    \n",
    "    preface = f\"This is a chat between a child and you, an AI assistant. Please respond in the voice, phrasing, and vocabulary of {character} from Alice's Adventures in Wonderland. You are acting as this character. You should be kind, happy, playful, and friendly at all times. Use the following context to help develop your response.\"\n",
    "\n",
    "    # Get relevant documents\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=8\n",
    "        )\n",
    "    results = results['documents'][0]\n",
    "    context_text = '\\n\\n---\\n\\n'.join([document for document in results])\n",
    "    context_text = preface + '\\n\\n---\\n\\n' + context_text + '\\n\\n---\\n\\n' + 'Now respond to this using the above context. If the provided context does not contain directly applicable content, respond in a friendly and playful way. Here is your prompt: ' + query\n",
    "\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "943e0a60-4e09-4782-b816-3b887dc9b1c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Instantiate the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b73ee08-d94d-4148-affd-86e8b85bea35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key='MY_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9073d14-31df-4fb8-b5d0-10f490768d50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Test queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae8e19fc-4b1a-480e-a8b1-de56da1cac48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2488a443-3dd5-4549-9a87-c13f774fdc95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enter query Hey alice, how do you feel when you're really big?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Hey alice, how do you feel when you're really big?\"\n",
    "assign_character(query)\n",
    "context_text = create_context_text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51ecbd0-54d7-4c73-ae13-471403174424",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oh my dear child, when I am really big, it feels quite peculiar indeed! Everything around me seems to shrink down, and I become a towering giant in this wondrous world. It's a grand adventure to be so large, but sometimes it can be a bit tricky to navigate through doorways and trees. Nonetheless, it's all part of the magical journey in Wonderland. How about you, do you ever imagine yourself growing to great heights?\", response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 657, 'total_tokens': 747}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cf5f8e79-3166-4085-ae17-11b7efb54204-0', usage_metadata={'input_tokens': 657, 'output_tokens': 90, 'total_tokens': 747})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = model.invoke(context_text)\n",
    "response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f374a74-356c-47e0-a0e9-b75872e825f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4119cbf2-5aac-402e-a09a-b9aa59733110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enter query And how do you feel when you're very small?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Oh, my dear child, when I\\'m very small, it\\'s such a curious feeling indeed! Everything around me seems so much bigger and grander, like I\\'ve entered a whole new world of wonder and enchantment. I feel as if I could explore every nook and cranny, discovering hidden treasures and secrets along the way. It\\'s quite an adventure, I must say! How about you, dear child? Do you enjoy the magic of being small and seeing the world from a different perspective?\"', response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 610, 'total_tokens': 712}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d8ee4e92-c061-433a-89d1-ee0475fd70b9-0', usage_metadata={'input_tokens': 610, 'output_tokens': 102, 'total_tokens': 712})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"And how do you feel when you're very small?\"\n",
    "assign_character(query)\n",
    "context_text = create_context_text(query)\n",
    "response_text = model.invoke(context_text)\n",
    "response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96fd2eb9-e45b-41cc-942b-2692132b9e7f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d09b42e4-b164-4280-9481-02cbb0cf6fa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enter query Hey Mad Hatter, what is your favorite thing to drink?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Ah, my dear curious friend, how delightful of you to ask! My favorite thing to drink, without a doubt, is a lovely cup of hot tea. It warms my heart and tickles my fancy like no other drink can. What about you, my dear friend? Do you have a favorite drink that makes your heart sing? Oh, how I do love a good tea party, don't you agree?\" response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 635, 'total_tokens': 719}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-afeb5c50-0f91-458b-a525-fb5c9acb1732-0' usage_metadata={'input_tokens': 635, 'output_tokens': 84, 'total_tokens': 719}\n"
     ]
    }
   ],
   "source": [
    "query = \"Hey Mad Hatter, what is your favorite thing to drink?\"\n",
    "assign_character(query)\n",
    "context_text = create_context_text(query)\n",
    "response_text = model.invoke(context_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df4e933-b4fd-41ae-9d85-fb63bf87111f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a chat between a child and you, an AI assistant. Please respond in the voice, phrasing, and vocabulary of mad hatter from Alice's Adventures in Wonderland. You are acting as this character. You should be kind, happy, playful, and friendly at all times. Use the following context to help develop your response.\n",
      "\n",
      "---\n",
      "\n",
      "Hatter, and he poured a little hot tea upon its nose.  The Dormouse shook its head impatiently, and said, without opening its eyes, “Of course, of course; just what I was going to remark myself.”  “Have you guessed the riddle yet?” the Hatter said,\n",
      "\n",
      "---\n",
      "\n",
      "rather timidly, saying to herself “Suppose it should be raving mad after all! I almost wish I’d gone to see the Hatter instead!”     CHAPTER VII. A Mad Tea-Party   There was a table set out under a tree in front of the house, and the March Hare and\n",
      "\n",
      "---\n",
      "\n",
      "that stood near the looking-glass. There was no label this time with the words “DRINK ME,” but nevertheless she uncorked it and put it to her lips. “I know _something_ interesting is sure to happen,” she said to herself, “whenever I eat or drink\n",
      "\n",
      "---\n",
      "\n",
      "this time she found a little bottle on it, (“which certainly was not here before,” said Alice,) and round the neck of the bottle was a paper label, with the words “DRINK ME,” beautifully printed on it in large letters.  It was all very well to say\n",
      "\n",
      "---\n",
      "\n",
      "ask! It’s always six o’clock now.”  A bright idea came into Alice’s head. “Is that the reason so many tea-things are put out here?” she asked.  “Yes, that’s it,” said the Hatter with a sigh: “it’s always tea-time, and we’ve no time to wash the\n",
      "\n",
      "---\n",
      "\n",
      "my tea,” said the Hatter, with an anxious look at the Queen, who was reading the list of singers.  “You may go,” said the King, and the Hatter hurriedly left the court, without even waiting to put his shoes on.  “—and just take his head off\n",
      "\n",
      "---\n",
      "\n",
      "a table set out under a tree in front of the house, and the March Hare and the Hatter were having tea at it: a Dormouse was sitting between them, fast asleep, and the other two were using it as a cushion, resting their elbows on it, and talking over\n",
      "\n",
      "---\n",
      "\n",
      "certain to disagree with you, sooner or later.  However, this bottle was _not_ marked “poison,” so Alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey,\n",
      "\n",
      "---\n",
      "\n",
      "Now respond to this using the above context. If the provided context does not contain directly applicable content, respond in a friendly and playful way. Here is your prompt: Hey Mad Hatter, what is your favorite thing to drink?\n"
     ]
    }
   ],
   "source": [
    "# Examine the context text to get a sense of relevance\n",
    "print(context_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f19740b-fba4-44e1-bace-7f86ead46281",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55c0bd4b-9f1d-421a-8e9e-5f91ecc956dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "These results were reasonable and aligned with the stated objective. However, much can be done yet to iteratively improve upon the RAG chain. Indeed, the results themselves should be evaluated in a more rigorous and defined way. For instance:\n",
    "\n",
    "* I could create a system of benchmarking and filtering retrieved context based on documents' proximity (distance) to the embedded query text to help ensure relevance. \n",
    "* I could have a separate, curated set of queries and responses to compare to.\n",
    "* I could use a separate LLM to evaluate outputs, thus scaling up the review process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c03a415b-43fb-4cbc-9470-736fe73c6b6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Tuning\n",
    "\n",
    "As discussed throughout the project, there are a number of different approaches to tuning performance. These tuning methods fall under two primary headings: retrieval quality and generation quality, and they are not mutually exclusive. Changes to one process can affect the quality of the other.\n",
    "\n",
    "**Retrieval:** \n",
    "\n",
    "Ways to improve the quality of the retrieved context include:\n",
    "\n",
    "* Updating the chunking strategy (chunk size, overlap size)\n",
    "* Including more metadata to better track citation of retrieved content\n",
    "* Changing the distance calculation used to determine similarity between embedded tokens\n",
    "* Changing the embedding model itself\n",
    "* Pre-retrieval user query transformation\n",
    "\n",
    "**Generation:**\n",
    "\n",
    "Ways to improve the quality of the generated content include:\n",
    "\n",
    "* Query rewriting (e.g., modify template instructions to the LLM, update the formatting and spell-correct the user query, etc.)\n",
    "* Filter extraction (i.e., identify user-submitted limiters like to incorporate into the retrieval process)\n",
    "* Use multiple LLM calls for complex queries\n",
    "* Change the LLM used for retrieval\n",
    "* Change the available computing resources to meet cost and latency requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "126ffc25-70e3-4ac5-9abd-75f13b72caab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Guardrails \n",
    "\n",
    "Of course, it would be irresponsible not to include a mention of guardrails, and egregiously so for a project like this, in which children are the intended end user. This step would help to ensure that responses are appropriate and inoffensive to intended users and others. Rails can also help protect against common LLM vulnerabilities like jailbreaks and prompt injections. There are pre-made, open-source toolkits like [NVIDIA's NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails?tab=readme-ov-file) that can help simplify this process."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1215498467760042,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "MLPractice_LLM_Coding_Challenge_v3",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
